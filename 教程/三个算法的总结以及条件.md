对于VXGI：
先进行三角形的体素化，然后再对体素纹理进行3D mipmap而不是clipmap
可以避免动态更新
只存储Albedo\*shadow Factor

VXGI 只做间接光，所以不考虑直接光照给予的光照Flux

体素化成为3D纹理以后，就是256\*256\*256的体素纹理了
很容易，直接把worldpos除以Scale，索引的UV是根据真实的Worldpos进行采样
使用采样器进行采样，而不是类似于LPV的直接索引，有一个插值的区别

可以索引到对应voxel，然后开始 voxel cone tracing
**没有递归**
目标是生成一张gbuffer，间接光分为specular以及diffuse




对于LPV：
把RSM的flux注入到volume 里面
如何实现以及索引：
把顶点从世界空间移动到LPV坐标系
这里是移动放缩到LPV坐标系
```cpp
output.cellPos = float4(int3(pos * LPV_SCALE + float3(LPV_DIM_HALF, LPV_DIM_HALF, LPV_DIM_HALF) + 0.5f * texel.normalWS), 1.0f);
```
然后缩放到原始的世界空间，借助0-1光栅化覆盖整个LPV的单片层


然后就是propagation阶段：
可以使用compute shader索引每一个voxel
我使用的是对于每一层，利用光栅化的特点，遍历每一个Voxel
这里使用的是int4类型，因为是针对每一个Voxel的，没有任何插值，是非常好的体素分离的教程
然后针对每一个体素，获得周围六个体素
每个体素5个面，1个正对面，4个包围面，相邻的面不算


LPV生成的是Voxel
最后直接读取对应的Voxel

RSM：
生成一张GBuffer图
把Worldpos变换到光源空间
然后采样周围的像素的flux，进行归一化
有一套严格的采样公式，包含了采样距离以及权重的关系

